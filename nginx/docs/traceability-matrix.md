# Matriz de Rastreabilidade Â· Hackathon One Sentiment API

Este documento amarra, em um Ãºnico lugar:

- requisitos funcionais (RF) e nÃ£o funcionais (RNF);
- casos de uso (UC);
- endpoints/componentes principais;
- cenÃ¡rios de teste planejados.

A ideia Ã© facilitar:

- ver se tudo o que foi pedido tem **um lugar na arquitetura**;
- ver se tudo o que foi implementado estÃ¡ **coberto por testes**.

---

## 1. ConvenÃ§Ãµes

- **RFxx** â€“ Requisito Funcional.
- **RNFxx** â€“ Requisito NÃ£o Funcional.
- **UCxx** â€“ Caso de Uso (ver docs/requisitos.md e diagramas de caso de uso).
- **T-API-xxx** â€“ Teste de API/Backend.
- **T-ML-xxx** â€“ Teste do microserviÃ§o de ML.
- **T-FE-xxx** â€“ Teste de frontend (fluxo de tela).
- **T-DB-xxx** â€“ Teste relacionado a banco de dados.
- **T-SEC-xxx** â€“ Teste de seguranÃ§a / robustez.

---

## 2. Mapa de Requisitos x Casos de Uso x Endpoints x Testes

### 2.1. Requisitos funcionais

> Lista baseada em `docs/requisitos.md` e nos diagramas de sequÃªncia.

#### RF01 â€“ Receber comentÃ¡rio de comprador

- **DescriÃ§Ã£o:** A API deve aceitar o envio de comentÃ¡rios (texto + nota) de um Cliente - Comprador associado a um produto.
- **Caso(s) de uso:**
    - UC01 â€“ Enviar comentÃ¡rio sobre produto.
- **Endpoint(s):**
    - `POST /api/v1/comentarios`
- **Componentes envolvidos:**
    - Frontend: `comprador.html`
    - Backend: `ComentarioController`, `ComentarioService`
    - DB: tabelas `comentario`, `cliente`, `produto`
- **Testes relacionados:**
    - T-FE-001 â€“ Fluxo comprador envia comentÃ¡rio vÃ¡lido.
    - T-API-001 â€“ POST /api/v1/comentarios com payload vÃ¡lido.
    - T-DB-001 â€“ InserÃ§Ã£o correta em `comentario`.

---

#### RF02 â€“ Validar entrada do comentÃ¡rio

- **DescriÃ§Ã£o:** Antes de aceitar um comentÃ¡rio, o backend deve validar campos obrigatÃ³rios e regras (texto obrigatÃ³rio, tamanho mÃ­nimo, nota 1â€“5, produto existente, etc.).
- **Caso(s) de uso:**
    - UC01 â€“ Enviar comentÃ¡rio sobre produto.
- **Endpoint(s):**
    - `POST /api/v1/comentarios`
- **Componentes envolvidos:**
    - Backend: camada de validaÃ§Ã£o (DTOs, Bean Validation)
    - DB: constraints de `comentario` (nota 1â€“5)
- **Testes relacionados:**
    - T-API-002 â€“ ComentÃ¡rio sem texto â†’ 400.
    - T-API-003 â€“ Nota fora de [1,5] â†’ 400.
    - T-API-004 â€“ Produto inexistente â†’ 404/400.
    - T-DB-002 â€“ InserÃ§Ã£o direta com nota invÃ¡lida deve falhar (CHECK).

---

#### RF03 â€“ Integrar com modelo de ML para anÃ¡lise de sentimento

- **DescriÃ§Ã£o:** Ao salvar um comentÃ¡rio vÃ¡lido, a API deve acionar o microserviÃ§o de ML para classificar o sentimento.
- **Caso(s) de uso:**
    - UC02 â€“ Classificar sentimento de comentÃ¡rio (ML).
- **Endpoint(s):**
    - interno: `POST /predict` (FastAPI ML)
- **Componentes envolvidos:**
    - Backend: `SentimentService`, cliente HTTP para ML
    - MicroserviÃ§o ML: FastAPI (`/predict`)
    - Modelo: arquivo `.pkl`
- **Testes relacionados:**
    - T-ML-001 â€“ POST /predict com texto positivo, resposta coerente.
    - T-ML-002 â€“ POST /predict com texto negativo, resposta coerente.
    - T-API-005 â€“ Backend chamando ML e recebendo resposta esperada.

---

#### RF04 â€“ Persistir resultado da anÃ¡lise de sentimento

- **DescriÃ§Ã£o:** O sistema deve registrar o sentimento, a probabilidade e o link para o comentÃ¡rio e modelo utilizados.
- **Caso(s) de uso:**
    - UC02 â€“ Classificar sentimento de comentÃ¡rio (ML).
    - UC03 â€“ Registrar resultados e notificaÃ§Ãµes.
- **Endpoint(s):**
    - `POST /api/v1/comentarios` (fluxo interno, apÃ³s o ML)
- **Componentes envolvidos:**
    - DB: tabelas `resultado_analise`, `modelo_ml`
    - Backend: `ResultadoAnaliseRepository`, `ModeloMLRepository`
- **Testes relacionados:**
    - T-DB-003 â€“ InserÃ§Ã£o correta em `resultado_analise`.
    - T-API-006 â€“ Verificar se, apÃ³s POST comentÃ¡rio, hÃ¡ um registro correspondente em `resultado_analise`.

---

#### RF05 â€“ Criar notificaÃ§Ãµes para comentÃ¡rios crÃ­ticos

- **DescriÃ§Ã£o:** Quando o resultado da anÃ¡lise indicar `sentimento = NEGATIVO` e `eh_critico = TRUE`, deve ser criada uma notificaÃ§Ã£o para o Cliente - Vendedor.
- **Caso(s) de uso:**
    - UC03 â€“ Registrar resultados e notificaÃ§Ãµes.
- **Endpoint(s):**
    - `POST /api/v1/comentarios` (fluxo interno, apÃ³s inserir `resultado_analise`)
- **Componentes envolvidos:**
    - DB: tabelas `notificacao`, `resultado_analise`, `produto`, `cliente`
    - Backend: `NotificacaoService`
- **Testes relacionados:**
    - T-API-007 â€“ ComentÃ¡rio com resultado NEGATIVO + crÃ­tico â†’ `NOTIFICACAO` criada.
    - T-DB-004 â€“ Integridade de FK `notificacao.resultado_id`.

---

#### RF06 â€“ Cadastrar e listar produtos de vendedor

- **DescriÃ§Ã£o:** Vendedores podem cadastrar produtos, e os produtos cadastrados podem ser listados tanto para o vendedor quanto para os compradores.
- **Caso(s) de uso:**
    - UC07 â€“ Cadastrar e gerenciar produtos.
- **Endpoint(s):**
    - `POST /api/v1/produtos`
    - `GET /api/v1/produtos`
    - `GET /api/v1/produtos?vendedorId=...`
- **Componentes envolvidos:**
    - Frontend: `vendedor.html`, `comprador.html`
    - Backend: `ProdutoController`, `ProdutoService`
    - DB: tabela `produto`
- **Testes relacionados:**
    - T-API-008 â€“ Criar produto vÃ¡lido.
    - T-API-009 â€“ Listar produtos por vendedorId.
    - T-FE-002 â€“ Vendedor vÃª seus produtos na tela.
    - T-FE-003 â€“ Comprador vÃª lista de produtos.

---

#### RF07 â€“ Exibir dashboard de sentimentos para o vendedor

- **DescriÃ§Ã£o:** O vendedor deve visualizar estatÃ­sticas agregadas de sentimentos, notas e comentÃ¡rios relacionados aos seus produtos.
- **Caso(s) de uso:**
    - UC04 â€“ Visualizar dashboard de sentimentos.
- **Endpoint(s):**
    - `GET /api/v1/stats?vendedorId=...`
- **Componentes envolvidos:**
    - Frontend: `vendedor.html` (dashboard)
    - Backend: `DashboardController` / `DashboardService`
    - DB: `comentario`, `resultado_analise`, `produto`
- **Testes relacionados:**
    - T-API-010 â€“ GET /stats retorna dados coerentes (nÃ£o vazios, somas batendo).
    - T-FE-004 â€“ Dashboard exibe cards/grÃ¡ficos corretos a partir do JSON de `/stats`.

---

#### RF08 â€“ Listar comentÃ¡rios analisados para o vendedor

- **DescriÃ§Ã£o:** Exibir para o vendedor a lista de comentÃ¡rios com notas, sentimento e probabilidade.
- **Caso(s) de uso:**
    - UC05 â€“ Visualizar comentÃ¡rios negativos/crÃ­ticos.
- **Endpoint(s):**
    - `GET /api/v1/comments?vendedorId=...`
- **Componentes envolvidos:**
    - Frontend: `vendedor.html` (lista de comentÃ¡rios)
    - Backend: `DashboardController` / `ComentarioController` (dependendo do design)
    - DB: `comentario`, `resultado_analise`
- **Testes relacionados:**
    - T-API-011 â€“ GET /comments filtra por vendedorId.
    - T-FE-005 â€“ Lista de comentÃ¡rios aparece com texto, nota, sentimento e probabilidade.

---

#### RF09 â€“ Listar notificaÃ§Ãµes e permitir marcÃ¡-las como lidas

- **DescriÃ§Ã£o:** O vendedor deve ver notificaÃ§Ãµes pendentes e poder marcÃ¡-las como lidas.
- **Caso(s) de uso:**
    - UC05 â€“ Visualizar comentÃ¡rios negativos/crÃ­ticos (via notificaÃ§Ãµes).
- **Endpoint(s):**
    - `GET /api/v1/notificacoes?vendedorId=...`
    - `PATCH /api/v1/notificacoes/{id}/ler`
- **Componentes envolvidos:**
    - Frontend: `vendedor.html` (lista de notificaÃ§Ãµes)
    - Backend: `NotificacaoController`, `NotificacaoService`
    - DB: tabela `notificacao`
- **Testes relacionados:**
    - T-API-012 â€“ GET /notificacoes retorna apenas notificaÃ§Ãµes do vendedor.
    - T-API-013 â€“ PATCH /notificacoes/{id}/ler atualiza `status = LIDA`.
    - T-FE-006 â€“ UI atualiza o estado visual ao marcar notificaÃ§Ã£o como lida.

---

#### RF10 â€“ Exportar dados de feedback em JSON

- **DescriÃ§Ã£o:** O vendedor deve conseguir exportar, em JSON, a lista de comentÃ¡rios e seus sentimentos para anÃ¡lise externa.
- **Caso(s) de uso:**
    - UC06 â€“ Exportar feedback em JSON.
- **Endpoint(s):**
    - `GET /api/v1/export?vendedorId=...`
- **Componentes envolvidos:**
    - Frontend: `vendedor.html` (botÃ£o "Exportar JSON")
    - Backend: `DashboardController` / `ExportService`
    - DB: `cliente`, `produto`, `comentario`, `resultado_analise`
- **Testes relacionados:**
    - T-API-014 â€“ GET /export retorna JSON com estrutura conforme especificaÃ§Ã£o.
    - T-API-015 â€“ Export respeita filtro por vendedorId.
    - T-FE-007 â€“ BotÃ£o de export inicia download do arquivo.

---

### 2.2. Requisitos nÃ£o funcionais (visÃ£o resumida)

> Detalhes completos em `docs/requisitos.md`. Aqui vai apenas o vÃ­nculo principal.

| RNF | DescriÃ§Ã£o resumida                                  | Ãrea principal        | Testes ligados           |
|-----|-----------------------------------------------------|-----------------------|--------------------------|
| RNF01 | API deve usar JSON em todas as comunicaÃ§Ãµes        | API / ML / Frontend   | T-API-001..015, T-ML-*   |
| RNF02 | Projeto deve usar Java 17 + Spring Boot            | Backend               | Verificado por build     |
| RNF03 | ML em Python 3 + scikit-learn + joblib            | Data Science / ML     | T-ML-001..003            |
| RNF04 | Banco PostgreSQL (ou H2 para dev)                 | DB / Backend          | T-DB-001..004            |
| RNF05 | NÃ£o expor segredos no Git                         | SeguranÃ§a / DevOps    | T-SEC-001 (revisÃ£o repo) |
| RNF06 | Respostas claras de erro (HTTP 4xx/5xx)           | API                   | T-API-002..004           |
| RNF07 | Simplicidade de execuÃ§Ã£o (poucos comandos)        | DevOps                | T-DEV-001..002           |
| RNF08 | Logging consistente por nÃ­vel (INFO/WARN/ERROR)   | Observabilidade       | T-LOG-001..003           |

---

## 3. CatÃ¡logo de testes referenciados

> Os detalhes (passos, dados de entrada, resultado esperado) podem ficar em `docs/test-strategy.md` / `docs/test-report.md`.  
> Aqui Ã© sÃ³ o *mapa*.

### 3.1. Testes de API (exemplos)

- **T-API-001** â€“ POST `/api/v1/comentarios` com payload vÃ¡lido â†’ 201 Created.
- **T-API-002** â€“ POST `/api/v1/comentarios` sem texto â†’ 400 Bad Request.
- **T-API-003** â€“ POST `/api/v1/comentarios` com nota invÃ¡lida â†’ 400 Bad Request.
- **T-API-004** â€“ POST `/api/v1/comentarios` com produto inexistente â†’ erro esperado.
- **T-API-005** â€“ Verificar se o backend chama `/predict` e trata a resposta.
- **T-API-007** â€“ CriaÃ§Ã£o de `NOTIFICACAO` apÃ³s comentÃ¡rio crÃ­tico.
- **T-API-010** â€“ GET `/api/v1/stats` retorna estatÃ­sticas coerentes.
- **T-API-012** â€“ PATCH `/api/v1/notificacoes/{id}/ler` atualiza status.

### 3.2. Testes de ML

- **T-ML-001** â€“ `/predict` com texto claramente positivo.
- **T-ML-002** â€“ `/predict` com texto claramente negativo.
- **T-ML-003** â€“ `/predict` com texto neutro / ambÃ­guo.

### 3.3. Testes de Frontend

- **T-FE-001** â€“ Fluxo â€˜comprador envia comentÃ¡rioâ€™.
- **T-FE-002** â€“ Fluxo â€˜vendedor cadastra produtoâ€™.
- **T-FE-004** â€“ Dashboard exibe cards de stats.
- **T-FE-006** â€“ Marcar notificaÃ§Ã£o como lida atualiza UI.

### 3.4. Testes de Banco

- **T-DB-001** â€“ InserÃ§Ã£o em `comentario` com nota vÃ¡lida.
- **T-DB-002** â€“ InserÃ§Ã£o em `comentario` com nota invÃ¡lida â†’ falha (CHECK).
- **T-DB-003** â€“ `resultado_analise` respeita FK para `comentario`.
- **T-DB-004** â€“ `notificacao` respeita FK para `cliente` e `resultado_analise`.

---

## 4. Como manter esta matriz atualizada

- Sempre que:
    - um novo RF for criado â†’ adicionar linha na matriz.
    - um novo endpoint for adicionado â†’ vincular ao RF/UC correspondente.
    - um novo teste for criado â†’ referenciar aqui.
- Recomenda-se atualizar esta matriz **junto com o PR** que introduz a mudanÃ§a, para evitar divergÃªncia entre cÃ³digo e documentaÃ§Ã£o.

```

---

```markdown
<!-- docs/dataset.md -->

# Dataset Â· Hackathon One Sentiment API

Este documento descreve como os dados usados no treinamento do modelo de anÃ¡lise de sentimentos sÃ£o escolhidos, tratados e conectados ao restante do sistema.

O objetivo Ã© que qualquer pessoa que olhe o projeto entenda:

- de onde vieram os dados;
- como foram limpos e transformados;
- quais sÃ£o as limitaÃ§Ãµes e cuidados Ã©ticos.

---

## 1. Objetivo do dataset

O modelo de Machine Learning do **Hackathon One Sentiment API** precisa aprender a classificar comentÃ¡rios em:

- Positivos
- Negativos
- (Opcional / Futuro) Neutros

O dataset deve, portanto:

- representar linguagem natural em portuguÃªs (pt-BR);
- conter textos com opiniÃ£o/avaliaÃ§Ã£o;
- ter rÃ³tulos de sentimento confiÃ¡veis.

---

## 2. Origem dos dados

A equipe de Data Science Ã© responsÃ¡vel por:

- selecionar um ou mais datasets pÃºblicos em portuguÃªs, por exemplo:
  - avaliaÃ§Ãµes de produtos;
  - comentÃ¡rios de clientes;
  - reviews de serviÃ§os.

Em versÃµes anteriores do projeto, foram considerados datasets do tipo:

- **AvaliaÃ§Ãµes em portuguÃªs (PT-BR)** liberadas em plataformas pÃºblicas como Kaggle.

> **Importante:**  
> Os dados devem ser sempre de fonte permitida, com uso aberto para fins educacionais/experimentais, respeitando termos de uso e privacidade.

---

## 3. Estrutura lÃ³gica dos dados brutos

De forma geral, espera-se que os dados brutos tenham pelo menos:

- **texto**: comentÃ¡rio, avaliaÃ§Ã£o ou frase de opiniÃ£o.
- **rÃ³tulo_original**: etiqueta de sentimento (por exemplo: `POS`, `NEG`, `NEU`).
- (Opcional) **nota**: score numÃ©rico (por exemplo, 1â€“5 estrelas).
- (Opcional) campos adicionais: id original, data, categoria de produto, etc.

Quando o dataset Ã© internalizado para o banco da aplicaÃ§Ã£o (`dataset_registro`), o mapeamento sugerido Ã©:

| Campo no dataset original | Campo em `dataset_registro` | ObservaÃ§Ã£o                              |
|---------------------------|-----------------------------|-----------------------------------------|
| texto / sentence / review | `texto`                     | conteÃºdo textual                         |
| label / sentiment         | `rotulo_original`           | ex.: `POS`, `NEG`, `NEU`                |
| rating / stars            | `nota`                      | se existir, 1â€“5                         |
| source / dataset_name     | `fonte`                     | ex.: nome do dataset ou URL de origem   |
| split (train/test/val)    | `split`                     | `TRAIN`, `TEST`, `VALID`                |
| id / row_id               | `id_externo`                | id no dataset de origem, se aplicÃ¡vel   |

---

## 4. Processo de preparaÃ§Ã£o (Data Preparation)

A preparaÃ§Ã£o tÃ­pica segue estes passos (registrados nos notebooks em `/datascience`):

### 4.1. Coleta

- Baixar o dataset bruto (ex.: CSV, JSON).
- Armazenar localmente em `/datascience/data/` (ignorado pelo Git se necessÃ¡rio).

### 4.2. Limpeza bÃ¡sica

- Remover linhas com:
  - texto nulo;
  - rÃ³tulo nulo;
  - textos extremamente curtos (ex.: menos de 3 caracteres).
- Opcionalmente:
  - remover duplicados exatos;
  - remover spam Ã³bvio (links repetidos, etc.).

### 4.3. Filtragem de idioma

- Sempre que possÃ­vel, garantir que os textos estejam em portuguÃªs (se o dataset for misto).
- Caso seja necessÃ¡rio filtro de idioma:
  - usar bibliotecas de language detection **apenas no notebook**, sem aumentar a complexidade do backend.

### 4.4. NormalizaÃ§Ã£o de rÃ³tulos

- Traduzir rÃ³tulos especÃ­ficos do dataset (`pos`, `negative`, `1`, `5`â€¦) para um conjunto comum:
  - `POS` â€“ positivo;
  - `NEG` â€“ negativo;
  - (Opcional) `NEU` â€“ neutro.
- Esse rÃ³tulo padronizado Ã© armazenado em `rotulo_original` em `dataset_registro`, e serve de base para treinar o modelo.

### 4.5. DivisÃ£o em treino / teste / validaÃ§Ã£o

- Definir, por exemplo:
  - 70% â†’ treino (`TRAIN`);
  - 15% â†’ validaÃ§Ã£o (`VALID`);
  - 15% â†’ teste (`TEST`).
- Gravar a partiÃ§Ã£o no campo `split`.

> A divisÃ£o exata pode ser ajustada pela equipe DS conforme o tamanho do dataset.  
> O importante Ã© manter **documentado** no notebook qual estratÃ©gia foi adotada.

---

## 5. InserÃ§Ã£o no banco da aplicaÃ§Ã£o (`dataset_registro`)

O preenchimento da tabela `dataset_registro` nÃ£o Ã© obrigatÃ³rio para o MVP, mas Ã© recomendado para:

- rastrear dados de treino dentro do contexto da aplicaÃ§Ã£o;
- possibilitar anÃ¡lises futuras e auditoria do modelo.

Fluxo sugerido:

1. A partir do notebook, exportar o dataset preparado (texto + rÃ³tulo + split + fonte + id_externo).
2. Usar um script Python ou um processo de ETL simples para:
   - conectar ao Postgres;
   - inserir registros em `dataset_registro`.
3. Garantir que:
   - `fonte` descreva claramente a origem;
   - `split` seja apenas `TRAIN`, `TEST` ou `VALID`;
   - `rotulo_original` mantenha os rÃ³tulos padronizados (`POS`, `NEG`, `NEU`).

---

## 6. Relacionamento com o modelo de ML

O dataset preparado serve como entrada para o pipeline:

- TokenizaÃ§Ã£o + vetorizaÃ§Ã£o (TF-IDF).
- Treino de modelo (ex.: RegressÃ£o LogÃ­stica).
- AvaliaÃ§Ã£o (accuracy, F1, etc.).
- SerializaÃ§Ã£o (arquivo `.pkl`).

A tabela `modelo_ml` registra:

- nome do modelo (ex.: `sentiment-logreg-tfidf`);
- versÃ£o (ex.: `v1`);
- mÃ©tricas principais (F1, acurÃ¡cia);
- data de treinamento;
- caminho do arquivo `.pkl`.

Dessa forma:

- `dataset_registro` â†’ representaÃ§Ã£o dos **dados**.
- `modelo_ml` â†’ representaÃ§Ã£o dos **modelos**.
- `resultado_analise` â†’ aplicaÃ§Ã£o do modelo aos comentÃ¡rios reais dos usuÃ¡rios.

---

## 7. LimitaÃ§Ãµes e viÃ©s

Alguns pontos importantes (para serem detalhados pela equipe DS de acordo com o dataset real):

- **DomÃ­nio do dataset:**  
  Se o dataset Ã© de reviews de produtos, o modelo pode:
  - funcionar muito bem para e-commerce;
  - mas pode nÃ£o generalizar tÃ£o bem para comentÃ¡rios polÃ­ticos, notÃ­cias, etc.

- **EquilÃ­brio de classes:**  
  Se houver muito mais positivos do que negativos, o modelo pode:
  - â€œtenderâ€ a classificar tudo como positivo;
  - exigir tÃ©cnicas como balanceamento ou ajuste de limiar.

- **Linguagem informal:**  
  GÃ­rias, abreviaÃ§Ãµes e ironia sÃ£o desafios naturais para modelos simples.

- **Sensibilidade Ã©tica:**  
  O modelo nÃ£o deve ser usado para:
  - decisÃµes de crÃ©dito;
  - triagem automÃ¡tica de usuÃ¡rios em situaÃ§Ãµes sensÃ­veis;
  - qualquer cenÃ¡rio onde erros de classificaÃ§Ã£o causem impacto grave.

---

## 8. Privacidade e Ã©tica

Mesmo usando dados pÃºblicos, o projeto adota alguns cuidados:

- NÃ£o copiar dados de usuÃ¡rios individuais sem permissÃ£o.
- Para datasets pÃºblicos, seguir os termos de uso originais.
- Em ambientes reais (fora do hackathon), seria necessÃ¡rio:
  - anonimizar dados pessoais;
  - evitar armazenar identificadores que permitam reidentificaÃ§Ã£o do autor.

---

## 9. AtualizaÃ§Ã£o do modelo e do dataset

Caso o modelo seja re-treinado com novos dados:

- criar uma nova entrada em `modelo_ml` com `versao` incrementada (ex.: `v2`);
- registrar:
  - nova data de treinamento;
  - novas mÃ©tricas;
  - referÃªncia Ã  nova fonte de dados (se houver);
- opcionalmente, registrar um subconjunto significativo do novo dataset em `dataset_registro`, indicando:
  - `fonte` adequada;
  - `split` correto.

---

## 10. Pontos a preencher pela equipe de Data Science

Assim que o dataset definitivo estiver escolhido e o notebook consolidado, recomenda-se complementar este documento com:

- nome exato do dataset usado;
- tamanho aproximado (nÃºmero de linhas);
- proporÃ§Ã£o de cada classe (quantos positivos/negativos/neutros);
- principais transformaÃ§Ãµes aplicadas (remoÃ§Ã£o de stopwords, stems, etc.);
- link direto para o notebook responsÃ¡vel pelo preparo.

```

---

````markdown
<!-- docs/coding-standards.md -->

# PadrÃµes de CÃ³digo e Estilo Â· Hackathon One Sentiment API

Este documento define convenÃ§Ãµes de cÃ³digo para as principais partes do projeto:

- Backend Java (Spring Boot)
- MicroserviÃ§o ML em Python (FastAPI)
- Frontend Web (HTML/CSS/JS)
- SQL / Banco de Dados
- Logs e mensagens

A ideia nÃ£o Ã© ser um manual de 200 pÃ¡ginas, mas sim um conjunto de regras claras o suficiente para deixar o cÃ³digo coeso e fÃ¡cil de manter.

---

## 1. PrincÃ­pios gerais

1. **Clareza acima de esperteza**  
   Nomeie variÃ¡veis, mÃ©todos e classes de forma que alguÃ©m lendo pela primeira vez entenda o propÃ³sito sem esforÃ§o.

2. **ConsistÃªncia > preferÃªncia pessoal**  
   Se uma convenÃ§Ã£o foi adotada (ex.: `camelCase` para campos JSON), siga o padrÃ£o em todo o projeto.

3. **SeparaÃ§Ã£o de responsabilidades**  
   - Backend: Controller â†” Service â†” Repository.  
   - Frontend: HTML (estrutura) â†” CSS (estilo) â†” JS (comportamento).  
   - ML: lÃ³gica de treino em notebooks, serviÃ§o de inferÃªncia no microserviÃ§o.

4. **Sem segredos no cÃ³digo**  
   Nunca hardcode usuÃ¡rio/senha, tokens ou chaves.

---

## 2. Backend Java (Spring Boot)

### 2.1. Estrutura de pacotes

PadrÃ£o sugerido (ajustado para a estrutura existente):

```text
backend/
â””â”€â”€ src/main/java/com/example/demo/
    â”œâ”€â”€ DemoApplication.java
    â”œâ”€â”€ domain/
    â”‚   â”œâ”€â”€ Cliente.java
    â”‚   â”œâ”€â”€ Produto.java
    â”‚   â”œâ”€â”€ Comentario.java
    â”‚   â”œâ”€â”€ ModeloML.java
    â”‚   â”œâ”€â”€ ResultadoAnalise.java
    â”‚   â”œâ”€â”€ Notificacao.java
    â”‚   â”œâ”€â”€ DatasetRegistro.java
    â”‚   â””â”€â”€ LogEvento.java
    â”œâ”€â”€ domain/enums/
    â”œâ”€â”€ repository/
    â”œâ”€â”€ service/
    â””â”€â”€ controller/
````

* `domain` â†’ entidades JPA e enums.
* `repository` â†’ interfaces `extends JpaRepository<...>`.
* `service` â†’ regras de negÃ³cio, integraÃ§Ã£o com ML, composiÃ§Ã£o de respostas.
* `controller` â†’ endpoints REST, apenas orquestrando chamada de serviÃ§os.

### 2.2. Nome de classes e mÃ©todos

* Classes:

    * `ClienteController`, `ProdutoService`, `ComentarioRepository`.
* MÃ©todos em serviÃ§os:

    * `criarProduto`, `listarProdutosDoVendedor`, `registrarComentario`, `gerarEstatisticas`, etc.
* MÃ©todos em controllers:

    * seguir verbos HTTP:

        * `createComentario`, `getStats`, `listComments`, etc.
    * ou delegar direto para o service mantendo nomes claros.

### 2.3. DTOs e JSON

* JSON enviado/recebido pelo frontend deve usar **camelCase**:

    * `tipoCliente`, `clienteVendedorId`, `clienteCompradorId`, `imagemUrl`, etc.
* DTOs devem refletir isso:

    * `ComentarioRequest { String texto; Integer nota; Long produtoId; Long clienteCompradorId; }`
* **Regra:** nÃ£o expor diretamente as entidades JPA no JSON de API; usar DTOs prÃ³prios quando houver risco de vazar campos internos.

### 2.4. ValidaÃ§Ã£o

* Usar anotaÃ§Ãµes de Bean Validation (`jakarta.validation`), por exemplo:

    * `@NotBlank` para texto;
    * `@Min(1)`, `@Max(5)` para nota;
    * `@NotNull` para IDs obrigatÃ³rios.
* Tratar erros de validaÃ§Ã£o com um handler central (ex.: `@ControllerAdvice`), retornando mensagens amigÃ¡veis em JSON.

### 2.5. Tratamento de erros

* NÃ£o devolver stacktrace bruto para o cliente.
* Usar exceÃ§Ãµes especÃ­ficas para:

    * recursos nÃ£o encontrados (`ResourceNotFoundException`);
    * erro de integraÃ§Ã£o com ML (`MlServiceException`);
    * validaÃ§Ã£o de negÃ³cio.
* Mapear essas exceÃ§Ãµes em respostas HTTP adequadas (400, 404, 500).

---

## 3. MicroserviÃ§o ML (Python + FastAPI)

### 3.1. Estrutura de arquivos

Modelo simples:

```text
ml_service/
â”œâ”€â”€ app.py
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ sentiment_model.pkl
â”‚   â””â”€â”€ vectorizer.pkl (se necessÃ¡rio)
â””â”€â”€ requirements.txt
```

Opcionalmente:

```text
ml_service/
â”œâ”€â”€ app.py
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ model_loader.py
â”œâ”€â”€ schemas/
â”‚   â””â”€â”€ sentiment.py
â””â”€â”€ model/
    â””â”€â”€ sentiment_model.pkl
```

### 3.2. Estilo de cÃ³digo

* PadrÃ£o PEP8 (nomes em `snake_case`).
* Usar **type hints** sempre que possÃ­vel:

  ```python
  from pydantic import BaseModel

  class SentimentRequest(BaseModel):
      text: str

  class SentimentResponse(BaseModel):
      label: str
      probability: float
      model_name: str
      model_version: str
  ```
* Separar:

    * modelos Pydantic (`schemas/`);
    * lÃ³gica de carregamento de modelo (`core/model_loader.py`);
    * rotas FastAPI (`app.py` ou `routes/`).

### 3.3. Carregamento do modelo

* Carregar o `.pkl` uma vez, na inicializaÃ§Ã£o do app, sempre que possÃ­vel:

  ```python
  from fastapi import FastAPI
  import joblib

  app = FastAPI()

  model = joblib.load("model/sentiment_model.pkl")

  @app.post("/predict")
  def predict(req: SentimentRequest) -> SentimentResponse:
      # ...
  ```
* Evitar recarregar o modelo a cada requisiÃ§Ã£o.

### 3.4. Logging no ML

* Usar o mÃ³dulo `logging` do Python.
* Logar:

    * carregamento do modelo;
    * requisiÃ§Ãµes recebidas (apenas metadados, nÃ£o o texto completo se for sensÃ­vel);
    * erros internos.

---

## 4. Frontend Web (HTML/CSS/JS)

### 4.1. Estrutura

```text
frontend/web/
â”œâ”€â”€ login.html
â”œâ”€â”€ comprador.html
â”œâ”€â”€ vendedor.html
â”œâ”€â”€ css/
â”‚   â””â”€â”€ styles.css
â””â”€â”€ js/
    â”œâ”€â”€ config.js
    â”œâ”€â”€ login.js
    â”œâ”€â”€ comprador.js
    â””â”€â”€ vendedor.js
```

### 4.2. Naming e organizaÃ§Ã£o

* IDs e classes:

    * usar nomes descritivos: `#form-login`, `#lista-produtos`, `.card-produto`, `.badge-notificacao`.
* JS:

    * uma funÃ§Ã£o por intenÃ§Ã£o:

        * `carregarProdutos()`, `enviarComentario()`, `carregarStats()`, etc.
    * evitar funÃ§Ãµes anÃ´nimas gigantes dentro de `onclick`; preferir `addEventListener`.

### 4.3. ConfiguraÃ§Ã£o centralizada

* Em `config.js`:

  ```js
  const API_BASE_URL = "http://localhost:8080/api/v1";

  const TipoCliente = {
    CLIENTE_COMPRADOR: "CLIENTE_COMPRADOR",
    CLIENTE_VENDEDOR: "CLIENTE_VENDEDOR",
    ADMIN: "ADMIN"
  };
  ```
* Demais scripts devem importar/consumir estas constantes.

### 4.4. Chamada Ã  API

* Usar `fetch` com `async/await`:

  ```js
  async function enviarComentario(payload) {
    const resp = await fetch(`${API_BASE_URL}/comentarios`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(payload)
    });

    if (!resp.ok) {
      // tratar erro
    }

    return await resp.json();
  }
  ```

* Tratar erros de rede e exibir mensagens amigÃ¡veis.

---

## 5. SQL e Banco de Dados

### 5.1. LocalizaÃ§Ã£o do schema

* DDL principal:

    * `ddl/schema-postgres.sql`
* AlteraÃ§Ãµes futuras:

    * podem ser registradas como comentÃ¡rios datados no prÃ³prio arquivo ou como novas migraÃ§Ãµes (se a equipe decidir usar Flyway/Liquibase futuramente).

### 5.2. ConvenÃ§Ãµes

* Nomes de tabelas em **snake_case**:

    * `cliente`, `produto`, `comentario`, `resultado_analise`, etc.
* Nomes de colunas em **snake_case**, coerentes com as entidades:

    * `cliente_vendedor_id`, `tipo_cliente`, `data_criacao`, etc.
* Constraints nomeadas:

    * `fk_<tabela>_<tabela_referenciada>`, `ck_<tabela>_<campo>`.

---

## 6. Logs e mensagens

### 6.1. NÃ­veis

* `INFO` â€“ eventos normais (criaÃ§Ã£o de comentÃ¡rio, acesso ao dashboard).
* `WARN` â€“ comportamentos estranhos, mas que nÃ£o quebram o sistema (tentativas invÃ¡lidas, timeouts recuperÃ¡veis).
* `ERROR` â€“ falhas que impedem o fluxo normal (erro ao chamar ML, falha de banco).

### 6.2. Origem

* `API`, `ML_SERVICE`, `FRONTEND`, `DB`, etc.
* Gravar origem de forma consistente em `log_evento.origem`.

### 6.3. PadrÃ£o de mensagem

* Mensagens sempre em portuguÃªs simples, claras e sem dados sensÃ­veis.
* Exemplo:

    * `"ComentÃ¡rio salvo com sucesso"`
    * `"Falha ao chamar ML_SERVICE /predict: timeout"`

---

## 7. ComentÃ¡rios e documentaÃ§Ã£o inline

* Evitar comentÃ¡rios redundantes:

    * ruim: `// soma 1 ao contador` para `contador++;`
* Bons comentÃ¡rios:

    * explicar **por que** algo Ã© assim (nÃ£o sÃ³ o â€œcomoâ€).
    * marcar TODOs bem especÃ­ficos: `// TODO: tratar cenÃ¡rio em que ML estÃ¡ fora do ar com fallback X`.

---

## 8. Ferramentas de formataÃ§Ã£o (opcional, recomendado)

Se o time concordar, podem ser adotadas ferramentas como:

* Java:

    * `mvn fmt:...` ou plugin de formataÃ§Ã£o no prÃ³prio IDE.
* Python:

    * `black` ou `isort` (opcional).
* JavaScript:

    * `prettier` (opcional).

O importante Ã© que a formataÃ§Ã£o fique consistente, mesmo que nÃ£o seja automatizada logo no MVP.

````

---

```markdown
<!-- CONTRIBUTING.md -->

# Contribuindo para o Hackathon One Sentiment API

Obrigado por querer contribuir ğŸ’™  
Este guia explica, de forma objetiva, como colaborar com o projeto sem se perder na estrutura ou quebrar o que jÃ¡ existe.

---

## 1. VisÃ£o rÃ¡pida do projeto

O repositÃ³rio Ã© organizado em mÃ³dulos:

```text
/
â”œâ”€â”€ backend/      # API Java + Spring Boot
â”œâ”€â”€ datascience/  # Notebooks e ML service em Python
â”œâ”€â”€ frontend/     # Interface Web (login, comprador, vendedor)
â”œâ”€â”€ docs/         # DocumentaÃ§Ã£o e diagramas
â”œâ”€â”€ ddl/          # schema-postgres.sql
â””â”€â”€ docker-compose.yml (futuro)
````

Antes de alterar qualquer coisa, Ã© uma boa ideia dar uma olhada em:

* `docs/README-docs.md`
* `docs/requisitos.md`
* `docs/arquitetura.md`

---

## 2. PrÃ©-requisitos bÃ¡sicos

Para desenvolver localmente, vocÃª vai precisar de:

* **Git**
* **Java 17** + Maven (ou wrapper do Maven)
* **Python 3.x** (para o ML service)
* **Node/Browser** (para testar o frontend estÃ¡tico)
* **PostgreSQL** (ou H2 configurado no Spring para dev)

---

## 3. Como rodar localmente (visÃ£o geral)

> Detalhes mais completos em `docs/devops-deploy.md`.

### 3.1. Backend

```bash
cd backend
./mvnw spring-boot:run
# ou
mvn spring-boot:run
```

### 3.2. ML Service (FastAPI)

```bash
cd datascience/ml_service
pip install -r requirements.txt
uvicorn app:app --reload --port 8000
```

### 3.3. Frontend

Abra os arquivos em:

* `frontend/web/login.html`
* `frontend/web/comprador.html`
* `frontend/web/vendedor.html`

ou use um servidor estÃ¡tico simples (ex.: `npx serve frontend/web`).

---

## 4. Fluxo de contribuiÃ§Ã£o (Git)

### 4.1. Branches

* `main` (ou `master`) deve ficar estÃ¡vel.
* Para contribuir:

    1. Crie uma branch a partir de `main`:

       ```bash
       git checkout main
       git pull
       git checkout -b feature/nome-da-feature
       ```
    2. Trabalhe nela.
    3. FaÃ§a commits pequenos e claros.
    4. Abra um Pull Request (PR).

SugestÃ£o de nomes de branch:

* `feature/backend-sentiment-endpoint`
* `feature/frontend-dashboard`
* `fix/ml-error-handling`

### 4.2. Commits

Usar mensagens claras, por exemplo:

* `feat: adicionar endpoint /api/v1/comentarios`
* `fix: corrigir validaÃ§Ã£o de nota`
* `docs: atualizar README de docs`
* `test: adicionar testes de integraÃ§Ã£o do ML`

---

## 5. CÃ³digo: onde mexer

### 5.1. Se vocÃª for mexer no Backend (Java)

* Controllers â†’ `backend/src/main/java/.../controller`
* Services â†’ `backend/src/main/java/.../service`
* Repositories â†’ `backend/src/main/java/.../repository`
* Entidades / enums â†’ `backend/src/main/java/.../domain/`

Antes de enviar PR:

* rode os testes:

  ```bash
  cd backend
  mvn test
  ```

### 5.2. Se vocÃª for mexer no ML Service (Python)

* Arquivo principal â†’ `datascience/ml_service/app.py`
* Modelo treinado â†’ `datascience/ml_service/model/sentiment_model.pkl`
* Notebooks â†’ `datascience/ml_notebooks/` ou `datascience/notebooks/`

Antes de enviar PR:

* rode o app localmente e teste `/predict` com alguns textos de exemplo.

### 5.3. Se vocÃª for mexer no Frontend

* Telas â†’ `frontend/web/*.html`
* CSS â†’ `frontend/web/css/styles.css`
* JS â†’ `frontend/web/js/*.js`

Cuide especialmente de:

* usar `API_BASE_URL` em `config.js`;
* nÃ£o duplicar lÃ³gica entre os arquivos JS.

---

## 6. Estilo e padrÃµes

* Siga as convenÃ§Ãµes em `docs/coding-standards.md`.
* MantÃ©m os nomes de entidades/DTOs alinhados com o domÃ­nio:

    * `Cliente`, `Produto`, `Comentario`, `ResultadoAnalise`, `Notificacao`, etc.
* Em JSON, use **camelCase**:

    * `clienteVendedorId`, `clienteCompradorId`, `imagemUrl`, `tipoCliente`.

---

## 7. Testes antes de enviar PR

Antes de abrir um Pull Request, tente:

* Backend:

    * `mvn test`
* ML service:

    * executar alguns testes manuais em `/predict` com cURL ou HTTP client;
* Frontend:

    * navegar pelos fluxos principais:

        * login â†’ comprador envia comentÃ¡rio;
        * login â†’ vendedor vÃª dashboard.

Se estiver adicionando novos endpoints ou fluxos:

* inclua pelo menos 1 ou 2 testes automatizados de exemplo (quando possÃ­vel);
* atualize `docs/test-strategy.md` e, se aplicÃ¡vel, `docs/test-report.md`.

---

## 8. DocumentaÃ§Ã£o

Se sua mudanÃ§a alterar:

* regras de negÃ³cio;
* fluxo de tela;
* endpoints;
* comportamento do modelo;

entÃ£o **atualize tambÃ©m**:

* `docs/requisitos.md` (se for um novo requisito ou uma mudanÃ§a relevante);
* `docs/arquitetura.md` ou algum diagrama em `docs/uml/`;
* `docs/traceability-matrix.md`, para manter a rastreabilidade alinhada.

---

## 9. DÃºvidas e alinhamento

Como este projeto foi pensado inicialmente para um hackathon, pode haver partes ainda nÃ£o finalizadas.
Antes de fazer uma mudanÃ§a grande:

* verifique a documentaÃ§Ã£o em `docs/`;
* veja os diagramas em `docs/uml/`;
* se estiver em equipe, combine rapidamente as decisÃµes (para evitar trabalho retrabalhado).

Obrigado por contribuir ğŸ’«
Toda melhoria de cÃ³digo, documentaÃ§Ã£o ou testes ajuda o projeto a ficar com cada vez mais cara de produÃ§Ã£o.
